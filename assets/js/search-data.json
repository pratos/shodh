{
  
    
        "post0": {
            "title": "Using returns library in Python to do functional programming",
            "content": "This is a personal experience of using returns and trying to learn functional programming paradigms in Python (in a professional setting). . Python &amp; Functional Programming . Python doesn&#39;t let you write functional code out of the box. There&#39;s a good chance, the &quot;functional&quot; code you might write isn&#39;t functional. I&#39;m definitely not here to discuss the intricacies of functional programming, just the experiences. . We are aware of map, filter, functools, itertools and lots of other niceties, which proxies for leveraging nicer parts of functional programming APIs. These let you do the functional things. But I wanted to satisfy my itch for abstractions that would help me leverage functional paradigms more accessible (maybe?). This led me to returns. . Did returns have returns? . First impressions and Railway Oriented Programming Pattern . returns is a nifty library that helps by providing functional constructs to help write &quot;better&quot; pythonic, functional code. . I was fascinated by Railway Oriented Programming (ROP) Pattern and frustrated by handling Exceptions in a nice way. Exception Handling is a real pain, when you want to make sure that the right messages and error code bubble up from the deep recesses of your controllers and services. . When an opportunity arose, I jumped at using returns. As a team, we had planned to use returns, but our attempts were half hearted at best. Using returns was a rocky, but enlightening experience. . Though I can&#39;t reveal the actual code, let me take you through a usage for returns. But first a tldr on Railway Oriented Programming Pattern . Many examples in functional programming assume that you are always on the ‚Äúhappy path‚Äù. But to create a robust real world application you must deal with validation, logging, network and service errors, and other annoyances. So, how do you handle all this in a clean functional way? - F# For Fun and Profit . %%html &lt;image src=&quot;https://miro.medium.com/max/1400/1*6bzo0qxaFYMCfYGuz7O4qw.png&quot;/&gt; . In short, ROP tells us to: . Create some sort of Result type that defines a 2 Track Output == Union[Success, Failure] | Use a bind function to convert all our functions to a two track output (even if they can&#39;t throw errors) | Compose all your functions via pipes | Add nice Error types as your write and refactor your code to handle those pesky Failures | . returns provides all of that in nicely packages containers with similar names like Result, Success and Failure (There&#39;s more but for scope we won&#39;t be covering the rest). returns readme has an excellent example on how to use those, the example used here is a modfied version. . Problem statement to solve . We&#39;ll be fetching data from football (soccer üëÄ) player data from fbref. We&#39;ll be extracting the data from html tables on the page and store it in a csv. Let&#39;s start by fetching Arsenal&#39;s 2022-23 season data via this url: link . Let&#39;s layout the steps that we&#39;ll need to perform inorder to get from our html page to a csv: . Fetch the html content via requests | Convert the html content to a BeautifulSoup for further extraction | Extract all the tables and combine all the statistics into one table | Save the table to a csv | . To simplify a few steps and for brevity, we&#39;ll be skipping a lot of the stats mapping code. . Make sure you install returns in your venv. . import sys sys.version . &#39;3.10.4 (main, Jun 1 2022, 18:38:27) [Clang 13.0.1 ]&#39; . Below is the code to parse data, you can skip this if you like . import requests from bs4 import BeautifulSoup from loguru import logger from returns.result import Result, Success, Failure def formatter(v: int|float) -&gt; int|float: if not v: return 0.0 return literal_eval(v) from enum import Enum from typing import Literal, List class TableId(Enum): standard_stats = &quot;stats_standard_9&quot; def __str__(self): return self.value from pydantic import BaseModel, validator from ast import literal_eval Nation = Literal[&quot;ENG&quot;, &quot;FRA&quot;, &quot;BRA&quot;, &quot;NOR&quot;, &quot;SUI&quot;, &quot;UKR&quot;, &quot;GHA&quot;, &quot;SCO&quot;, &quot;BEL&quot;, &quot;EGY&quot;, &quot;JPN&quot;, &quot;POR&quot;, &quot;CIV&quot;, &quot;USA&quot;] Position = Literal[&quot;GK&quot;, &quot;DF&quot;, &quot;MF&quot;, &quot;FW&quot;] class Age(BaseModel): year: int months: int @validator(&quot;*&quot;, pre=True, always=True) def formatter(cls, v): if not v: return 0.0 return literal_eval(v.lstrip(&quot;0&quot;)) @validator(&quot;months&quot;, always=True) def age_convertor(cls, v): return round(v / 30, 0) class BasicProfile(BaseModel): player_name: str nation: Nation position: List[Position] age: Age class PlayingTime(BaseModel): matches_played: int minutes_played: int starts: int nineties: int _formatter = validator(&quot;*&quot;, pre=True, allow_reuse=True)(formatter) class Performance(BaseModel): goals_scored_or_allowed: int assists: int non_penalty_goals: int penalties: int yellow_cards: int red_cards: int _formatter = validator(&quot;*&quot;, pre=True, allow_reuse=True)(formatter) class PerformancePer90(BaseModel): goals: float assists: float _formatter = validator(&quot;*&quot;, pre=True, allow_reuse=True)(formatter) class XPPerformance(BaseModel): expected_goals: float non_penalty_expected_goals: float expected_assists: float non_penalty_goals_expected_and_assists: float _formatter = validator(&quot;*&quot;, pre=True, allow_reuse=True)(formatter) class XPPerformancePer90(XPPerformance): pass class StandardStats(BaseModel): player_profile: BasicProfile playing_time_overall: PlayingTime player_performance: Performance player_performance_per_90: PerformancePer90 player_xp: XPPerformance player_xp_per_90: XPPerformancePer90 arsenal_url = &quot;https://fbref.com/en/squads/18bb7c10/Arsenal-Stats&quot; . . def fetch_html_content(url: AnyHttpUrl) -&gt; BeautifulSoup: resp = requests.get(url, timeout=20) return BeautifulSoup(resp.content, &quot;html.parser&quot;) html_data = fetch_html_content(url=arsenal_url) * Extracting all the tables - We&#39;ll just extract one for brevity - Excuse the multiple list comprehensions, isn&#39;t optimized üò¨ #collapse-hide def extract_and_format_fbref_data(table_id: TableId, html_data: BeautifulSoup) -&gt; List[StandardStats]: standard_stats_list = [] standard_stats_table = html_data.find(id=table_id) standard_stats_table.find_all(&quot;caption&quot;)[0].text table_headers = [row.text.lower() for row in standard_stats_table.find_all(&quot;tr&quot;)[1] if row != &#39; &#39;] table_data = standard_stats_table.find_all(&quot;tbody&quot;)[0] for idx, row in enumerate(table_data.find_all(&quot;tr&quot;)): stripped_data = [data.text for data in row] age = Age( year=stripped_data[3].split(&quot;-&quot;)[0], months=stripped_data[3].split(&quot;-&quot;)[1] ) basic_profile = BasicProfile( age=age, player_name=stripped_data[0], nation=stripped_data[1].split(&quot; &quot;)[1], position=[pos.strip() for pos in stripped_data[2].split(&quot;,&quot;)] ) playing_time = PlayingTime( matches_played=stripped_data[4], starts=stripped_data[5], minutes_played=stripped_data[6], nineties=stripped_data[7] ) performance = Performance( goals_scored_or_allowed=stripped_data[8], assists=stripped_data[9], non_penalty_goals=stripped_data[10], penalties=stripped_data[11], yellow_cards=stripped_data[13], red_cards=stripped_data[14] ) performance_per90 = PerformancePer90( goals=stripped_data[15], assists=stripped_data[16], ) xp_performance = XPPerformance( expected_goals=stripped_data[20], non_penalty_expected_goals=stripped_data[21], expected_assists=stripped_data[22], non_penalty_goals_expected_and_assists=stripped_data[23], ) xp_performance_per90 = XPPerformancePer90( expected_goals=stripped_data[24], non_penalty_expected_goals=stripped_data[25], expected_assists=stripped_data[26], non_penalty_goals_expected_and_assists=stripped_data[27], ) standard_stats = StandardStats( player_profile=basic_profile, playing_time_overall=playing_time, player_performance=performance, player_performance_per_90=performance_per90, player_xp=xp_performance, player_xp_per_90=xp_performance_per90 ) standard_stats_list.append(standard_stats) return standard_stats_list parsed_data = extract_and_format_fbref_data(table_id=TableId.standard_stats.value, html_data=html_data) import csv import json class JsonWriter: def __init__(self, path: str, data: List[StandardStats]): self._path = path self._data = data def save(self) -&gt; None: with open(self._path, &quot;w&quot;, newline=&quot;&quot;) as json_file: json.dump([stat.dict() for stat in self._data], json_file) def save_data(writer: CSVWriter | JsonWriter, path: str, data: List[StandardStats]) -&gt; str: writer_inst = writer(path=path, data=data) writer_inst.save() return f&quot;Successfully saved data to {path}&quot; save_data(JsonWriter, path=&quot;../data/arsenal_standard_stats.json&quot;, data=parsed_data) . . How do we bind these and make sure that we follow ROP? . Two magic keywords: @safe and bind (or flow). . @safe is basically an exception handler decorator. Any exception caught will return a Failure container. For the happy path, we&#39;d have Success container with our output There&#39;s also @impure_safe which is a more explicit way to tell readers that this piece of code might fail or result might be different for the same request. DB Query, API calls, etc | . | flow (or pipe) act as pipelines for stiching functions together using bind | . from returns.pipeline import flow from returns.pointfree import bind from returns.result import safe from returns.io import impure_safe, IOResult from returns.curry import curry @impure_safe def fetch_html_content(url: AnyHttpUrl) -&gt; BeautifulSoup: resp = requests.get(url, timeout=20) return BeautifulSoup(resp.content, &quot;html.parser&quot;) @safe def extract_and_format_fbref_data(table_id: TableId, html_data: BeautifulSoup) -&gt; List[StandardStats]: standard_stats_list = [] ... return standard_stats_list @safe def save_data(writer: CSVWriter | JsonWriter, path: str, data: List[StandardStats]) -&gt; str: writer_inst = writer(path=path, data=data) writer_inst.save() return f&quot;Successfully saved data to {path}&quot; def fetch_standard_stats(url: AnyHttpUrl, table_id: TableId, output_path: str) -&gt; IOResult[Success, Failure]: return flow( url, fetch_html_content, bind(partial(extract_and_format_fbref_data, table_id)), bind(partial(partial(save_data, JsonWriter), output_path)) ) . Let me lay out the flow pipeline in fetch_standard_stats: . flow is a pipeline that takes in the attribute(s) (url here) for the first function: fetch_html_content. | The first function throws out a Success container (if no exceptions) that is consumed by extract_and_format_fbref_data. Since the 2nd function has multiple arguments, we are using partial to bind together arguments. | . bind(partial(extract_and_format_fbref_data, table_id)) . Above is equivalent to: . function_1 = partial(extract_and_format_fbref_data, table_id) function_2 = bind(function_1, &#39;Success: html_data&#39;) . function_2 above will emit: Success: parsed_data which would be input for the next bind function. | . A successful outcome would be as below . fetch_standard_stats( arsenal_url, TableId.standard_stats, &quot;../data/arsenal_standard_stats.json&quot; ) . &lt;Success: Successfully saved data to ../data/arsenal_standard_stats.json&gt; . If we mess up something in the arsenal_url? Let&#39;s check what the output would be: . fetch_standard_stats(&quot;https://localhost:9200&quot;) . &lt;Failure: HTTPSConnectionPool(host=&#39;localhost&#39;, port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, &#39;[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:997)&#39;)))&gt; . As expected, we get a HTTPSConnectionPool error that we get out without writing excessive try-catch blocks. We can easily bubble these errors 2-3 levels up using bindings and making the code cleaner. . At any step of the pipeline, Failure container would throw a nice message and we can do the rest. Obviously, there&#39;s a few more nuanced implementations for complex pipelines. E.g. While doing a DB operation if the query sends no result or API request is unsuccessful with a valid status code. All those might need more rejig of the code. . How do we fetch the output from Success container? . In our case, the final step throws a Success container with response str embedded. If we want to send this result back via API or do another set of operations on it, it is easy to do with result._inner_value . success_result = fetch_standard_stats( arsenal_url, TableId.standard_stats, &quot;../data/arsenal_standard_stats.json&quot; ) . success_result._inner_value . &#39;Successfully saved data to ../data/arsenal_standard_stats.json&#39; . ._inner_value could be anything that you want to share: dict, str, Object, Query row, json. This opens up a lot of avenues to play around with pydantic Models or dataclasses that help standardize API responses, sql orm models! . Is is any good to use? . returns doesn&#39;t have a great documentation. It would be hard to blame the maintainers coz one needs to atleast understand basics of functional programming (currying, partial, Optional, Maybe containers). A comprehensive documentation/examples about more real life usage could help more non-chad devs like us. . Combined with OOPS, returns would definitely be an alternative to write cleaner, readable code. One could also ditch returns entirely and work with functools, dataclasses and types in python to write similar helpers, decorators in vanilla python. Maybe that could be another blog post. . The above code surely can be much better, still improving on how to write code. Would love to hear feedback on the code and this blogpost! . Appendix . Functional programming: Computerphile | functools.partial | 3 Simple ideas from functional programming to improve your code - Arjan Codes | Functional Programming in Python: Currying | .",
            "url": "https://pratos.github.io/shodh/functional%20programming/python/railway%20oriented%20programming/2022/09/09/returns-functional-programming.html",
            "relUrl": "/functional%20programming/python/railway%20oriented%20programming/2022/09/09/returns-functional-programming.html",
            "date": " ‚Ä¢ Sep 9, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "DataViz Dashboards using Python, the Resources",
            "content": "All the Data Science enthusiasts would agree on the fact that: Data Visualization using Python is hard!. We‚Äôll look at some means via which we can do data visualization &amp; dashboards. . RShiny, oh my precious! . . R rules in the Data Visualization space, to make those plots more user friendly, we have RShiny. Hands-down the best tool to do exploratory data analysis. . But there‚Äôs still a catch here, RShiny is still unintuitive for someone not familiar with HTML,CSS especially Bootstrap. With the reactive programming concept, mastering RShiny is a difficult task. Plus, the packaging and using it in for a production environment (and expectations of clients for RShiny to be a good looking interface) makes it difficult. RStudio‚Äôs offering, RShiny Server is a good choice, but to purchase the enteprise version a small startup may have to rent their existing rented workspace (RStudio Pricing). There‚Äôs a free version too, but again setup headaches. . Popular Visualization Tools, mainstream‚Ä¶ . . Tableau, PowerBI and Qlikview are choices, but the licence costs would drain all the money. Not like a Data Science guy would purchase hefty licences to make dashboards‚Ä¶not everyone makes dashboards everyday! So there‚Äôs an option of going the Javascript way! But‚Ä¶ . - ok, who&#39;s ready to learn javascript?[30 hands go up]- who&#39;s going to give it more than 1 week?[30 hands go down]Next day: &quot;JS SUCKS&quot; . &mdash; I Am Devloper (@iamdevloper) June 14, 2017 JavaScript, FTW! . . Javascript for DataViz is a crowded space with lots of libraries (as expected), with varying amounts of abstractions. The most popular one is D3js. You can check out the rest at this link. . Python? whoa stop right there! . . For Python, there are libraries that help you in Data Visualization. Most popular ones are: matplotlib and its abstraction: seaborn. . Matplotlib can be considered as a low abstraction level plotting tool that helps anyone to build charts just like how you build Lego structures. It is painstaking‚Ä¶your eyes will bleed by the time your finish the graph‚Ä¶but it is worth the pain‚Ä¶if you aren‚Äôt on a deadline. . Quick, dirty plotting that‚Äôs a feature of ggplot2 or R, for that matter, isn‚Äôt exactly for Python. It follows the same Grammar of Graphics philosophy, but there‚Äôs a steep learning curve. . Seaborn on the other hand is pretty much a decent library to start off. The official page describes it as: . Seaborn is a library for making attractive and informative statistical graphics in Python. It is built on top of matplotlib and tightly integrated with the PyData stack, including support for numpy and pandas data structures and statistical routines from scipy and statsmodels. . There‚Äôs another way through which the pain of quick, dirty data visualization is possible. It is possible via pandas‚Äô inbuilt plotting functions for dataframes. . Plotly has excellent APIs to make your static Python plots interactive. That‚Äôs another option, also good guys at Plotly have released a framework to create dashboards: Dash, which has an HTML-Python hybrid interface. . Now all this was all good, what if we want to integrate everything in a dashboard using just python. Making a dashboard in Python! That too pure Python code? You must be kidding, right? . That‚Äôs what I thought when I started out, but who knew there‚Äôs always hope! . If you want to get an idea about Python Visualization landscape, watch Jake VanderPlas‚Äô: The Python Visualization Landscape at PyCon 2017 . Bokeh . . Bokeh is a Python interactive visualization library that targets modern web browsers for presentation. Its goal is to provide elegant, concise construction of novel graphics in the style of D3.js, and to extend this capability with high-performance interactivity over very large or streaming datasets. Bokeh can help anyone who would like to quickly and easily create interactive plots, dashboards, and data applications. . Sounds fun, but first time I tried it‚Ä¶not that great! . Recently, revisited back again to work on interactive Jupyter notebooks. I went from being excited about Dash, to crying and bookmarking D3js tutorials. Things weren‚Äôt the same for me, I was sure Bokeh wasn‚Äôt okay. . Then deadlines came up and I had to act fast. Fired up the browser, YouTubed the hell out and came across Bokeh videos (via the NYC Taxi Data visualizations by Continuum). This post isn‚Äôt about coding out a Bokeh plot or Dashboard, but providing resources (and bitching about other languages/tools). . Watch for Inspiration | Understanding the Bokeh basics - Strata conference 2016 | Sarah Bird‚Äôs Getting started with Bokeh | Sarah Bird‚Äôs Bokeh for Web Developers | Casey Clements‚Äô Bokeh basics | Bryan Van de Ven - Bokeh for Data Applications and Visualization | . Some github resources: . Bokeh notebooks | Bokeh slides | Bokeh nbviewer | . Even if blogs/videos are a great resource to start off, project documentation is the best resource if you get stuck. Bokeh documentation is fairly good, sometimes the whole searches are a bit of a pain. Said that, it is still great! . Bokeh User Guide | Bokeh Gallery - Inspired from RShiny Gallery | . One great advantage of Bokeh is it plays nicely along with other libraries: Leveraging Libraries . You can convert your exisiting matplotlib code to bokeh. . For large datasets, there‚Äôs always a problem of well‚Ä¶large number of data points that can‚Äôt be fitted on a 2D space. We have a lot of ways through which we can do it. Continuum has open sourced libraries that make this task easy: . Datashader | Dask | Holoviews | . A few advanced notebooks that could help: . Common pitfalls | Datashader: Webinar | How to meaningfully use datashader | . By all means, these tools are something that I know of and does not include a lot of tools. Do comment in to add a few! .",
            "url": "https://pratos.github.io/shodh/2017/08/11/data-dashboards-python.html",
            "relUrl": "/2017/08/11/data-dashboards-python.html",
            "date": " ‚Ä¢ Aug 11, 2017"
        }
        
    
  
    
        ,"post2": {
            "title": "Machine Learning Resources for Python [Basic]",
            "content": "There are lots of github repositories and blogs that have more exhaustive resources than what I‚Äôve put down here that covers a whole lot. But these would be good to start off, I‚Äôll put together an intermediate list in the next post. . Understanding Anaconda distribution &amp; using it for Machine Learning(ML) . As someone starting off with ML &amp; using Python to do it, you will have to understand that ML or Data Science is more of sharing, collaboration and involves you having to share all your findings/research/outcomes to the stake-holders or engineering folks that would use it. Anaconda distribution is one such means through which you will keep yourself sane as well as keep others sane. . Right from the start, try using Jupyter notebooks rather than an IDE, this will help you to explore more and document your findings/issues/quirks without leaving the notebook. . Installation NOTE: If you have Windows, just download the conda installer for Windows and install .exe file | NOTE: If you have Ubuntu/Mac, use wget &lt;url link&gt; | . | Miniconda installation -alternate space saver for Anaconda, I‚Äôll suggest this | Miniconda .exe files | Understanding to use Jupyter notebooks | Conda myths and misconceptions - Must read | . Basics of Python: . JM Portilla course notebooks | Python Programming - MUST READ | Python Programming - sentdex videos MUST WATCH | . Extra Resources: . Learning how to write Markdown Documents - Essential | Awesome Python - github | Code Handbook for Python | . Statistics &amp; Machine Learning basics . Brandon Foltz‚Äôs Stats videos - MUST WATCH | What is Machine Learning | Analytics Vidhya ML path using Python NOTE: Please do not attempt Kaggle competitions now, it would hinder your progress. Go through the basics first and then attempt Kaggle competitions. | . | Coursera Andrew NG videos - Watch these after you are done with all the courses | . Python for Data Science . You have to learn about a few libraries that are core pillars of Python: . NOTE: Click here for an umbrella source for Data Science using Python . Numpy Numpy basics | Numpy Tutorial - cs231n | . | Pandas Pandas basics | Pandas by Greg Reda | Pandas Troylabs | Pandas by Data Camp | . | Matplotlib Matplotlib - pyplot | Matplotlib by Nicolas Rougier | Matplotlib by Datacamp | Matplotlib by Jake Vander Plass - This guy is good! | . | Seaborn Seaborn Entire tutorial - official blog | Seaborn tutorial by Elite Data Science | . | Scikit-Learn NOTE: You‚Äôll be able to appreciate Scikit learn after you know the theory of Machine Learning (ML) | Scikit learn basics by Data Camp | ML Mastery by Jason Bronwlee - Basics SKLearn | . | . A few blogs that regularly you will need to refer regularly . Analytics Vidhya - They have decent ML/Data Science related articles for theory and handson | DataCamp | Dataquest | yHat blog | Chris Albon - Whenever you get stuck,don‚Äôt know a syntax | . Generic Reading . Role of Data Science team | What are the steps for Data Analysis | . Regular Reading . You‚Äôll need to make sure you read at least one article related to ML/DL/Data Science EVERYDAY. You understand it or not is a different thing, but it would help you to think about why/what/how. If you understand, it would add more to your understanding, if not then you can read more about it. Few reading feeds you can follow are: Medium publication - Becoming Human (ML/DL/Data Science) | Medium publication - Towards Data Science ((ML/DL/Data Science ‚Äì recommended) | Medium publication - freeCodeCamp (Software Engg, ML, DL ‚Äì recommended) | Medium publication - HackerNoon (Software Engg, ML, DL ‚Äì recommended) | . | . Books that would help . Introduction to ML using Python by Sarah Guido &amp; Andreas Mueller | . Do let me know if this a good list for a beginner or would have to add/remove anything. Enjoy &amp; learn! .",
            "url": "https://pratos.github.io/shodh/2017/07/22/python-machine-learning-basics.html",
            "relUrl": "/2017/07/22/python-machine-learning-basics.html",
            "date": " ‚Ä¢ Jul 22, 2017"
        }
        
    
  
    
        ,"post3": {
            "title": "Understanding OpenCV - Code Snippets",
            "content": "I made a jump directly to Computer Vision by using Deep Learning, mostly using CNNs &amp; Keras. CNN &amp; Keras are like Adam West‚Äôs Batman &amp; Burt Ward‚Äôs Robin, much simpler &amp; fun days of the bat vigilante. . ¬† . Source: The Mary Sue . But with a lot of image pre-processing (apart from Keras‚Äô own functions) crucial to the final output, I searched for a good library to do it. skimage is a great library for doing image pre-processing. It packs enough to get you started, but the most widely used is OpenCV. . OpenCV has a bit of steep learning curve, but once you get used to it there‚Äôs no feeling like any other. While preparing this notebook, I never intended it to be a blogpost. Things started off with creating snippets off the official library &amp; with inputs from blogposts by PyImageSearch which is frankly the most comprehensive blog for Computer Vision. Let‚Äôs dive into the actual notebook. . . Downloading the image . !curl &quot;https://raw.githubusercontent.com/pratos/pratos.github.io/master/images/screenshot1.png&quot; &gt; screeshot.png . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 74844 100 74844 0 0 73184 0 0:00:01 0:00:01 --:--:-- 78866 . !ls . Amazon Kaggle EDA.ipynb Pre Processing Notebook.ipynb Image Processing using OpenCV - Part 1.ipynb screeshot.png . . Import the image through OpenCV . %matplotlib inline import matplotlib.pyplot as plt import signal import numpy as np import cv2 . Open an image using cv2.imread() Import a color image: cv2.IMREAD_COLOR (arg = 1) | Import a color image: cv2.IMREAD_GREYSCALE (arg = 0) | Import a color image: cv2.IMREAD_UNCHANGED (arg = -1) | . | . screen_img = cv2.imread(&#39;./screeshot.png&#39;, 1) . plt.imshow(screen_img) plt.xticks([]), plt.yticks([]) # to hide tick values on X and Y axis plt.show() . . Drawing shapes on an image . # Create a black image img = np.zeros((512,512,3), np.uint8) . # Draw a diagonal white line with thickness of 6 px cv2.line(img, (0,0),(511,511),(255,255,255),6) . array([[[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0]], [[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0]], [[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0]], ..., [[ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]]], dtype=uint8) . plt.imshow(img) . &lt;matplotlib.image.AxesImage at 0x7f3c2ec681d0&gt; . . # cv2.rectangle(image, dim1-coordinates, dim2-coordinates, color, px size) cv2.rectangle(img, (250, 250), (300, 300), (255,255,255), 4) . array([[[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0]], [[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0]], [[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0]], ..., [[ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[ 0, 0, 0], [ 0, 0, 0], [ 0, 0, 0], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]]], dtype=uint8) . plt.imshow(img) . &lt;matplotlib.image.AxesImage at 0x7f3c2ec48e10&gt; . . Accessing Image properties . img.shape . (512, 512, 3) . type(img) . numpy.ndarray . Image ROI (Region of Image) . # Getting google logo logo = screen_img[200:400, 500:900] . plt.imshow(logo) . &lt;matplotlib.image.AxesImage at 0x7f3c2e5264e0&gt; . . Image arithmatic . x = np.uint8([250]) . x . array([250], dtype=uint8) . y = np.uint8([10]) y . array([10], dtype=uint8) . x+y . array([4], dtype=uint8) . cv2.add(x, y) . array([[255]], dtype=uint8) . There is a difference between OpenCV addition and Numpy addition. OpenCV addition is a saturated operation while Numpy addition is a modulo operation. . Blending 2 images . It is a type of Image addition, but different weights are provided to the pixels (to add opaqueness/transparency). . The equation is: . $g(x) ;= ;(1- alpha)f_{0}(x) ;+ ;{ alpha}f_{1}(x)$ . Varying $ alpha$ from 0 $ rightarrow$ 1, we can change the blending. . The operation is performed using cv2.addWeighted(). . ! wget &quot;http://www.satupedia.com/wp-content/uploads/2017/03/arsenalb40ddb51f5f44099ae80dc5d7e1c59880524d72a24e0d4033ef4c60a39c7dcf1_large.jpg&quot; . --2017-06-15 00:04:49-- http://www.satupedia.com/wp-content/uploads/2017/03/arsenalb40ddb51f5f44099ae80dc5d7e1c59880524d72a24e0d4033ef4c60a39c7dcf1_large.jpg Resolving www.satupedia.com (www.satupedia.com)... 45.32.102.146 Connecting to www.satupedia.com (www.satupedia.com)|45.32.102.146|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 57840 (56K) [image/jpeg] Saving to: ‚Äòarsenalb40ddb51f5f44099ae80dc5d7e1c59880524d72a24e0d4033ef4c60a39c7dcf1_large.jpg‚Äô arsenalb40ddb51f5f4 100%[===================&gt;] 56.48K 286KB/s in 0.2s 2017-06-15 00:04:50 (286 KB/s) - ‚Äòarsenalb40ddb51f5f44099ae80dc5d7e1c59880524d72a24e0d4033ef4c60a39c7dcf1_large.jpg‚Äô saved [57840/57840] . !wget &quot;http://upload.inven.co.kr/upload/2014/05/08/bbs/i3945135106.jpg&quot; . --2017-06-15 00:04:52-- http://upload.inven.co.kr/upload/2014/05/08/bbs/i3945135106.jpg Resolving upload.inven.co.kr (upload.inven.co.kr)... 114.31.34.170 Connecting to upload.inven.co.kr (upload.inven.co.kr)|114.31.34.170|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 445045 (435K) [image/jpeg] Saving to: ‚Äòi3945135106.jpg‚Äô i3945135106.jpg 100%[===================&gt;] 434.61K 290KB/s in 1.5s 2017-06-15 00:04:56 (290 KB/s) - ‚Äòi3945135106.jpg‚Äô saved [445045/445045] . !mv arsenalb40ddb51f5f44099ae80dc5d7e1c59880524d72a24e0d4033ef4c60a39c7dcf1_large.jpg arsenal.jpg . !mv i3945135106.jpg cesc.jpg . !ls . Amazon Kaggle EDA.ipynb Image Processing using OpenCV - Part 1.ipynb arsenal.jpg Pre Processing Notebook.ipynb cesc.jpg screeshot.png . img1 = cv2.imread(&#39;arsenal.jpg&#39;, 1) img2 = cv2.imread(&#39;cesc.jpg&#39;, 1) . plt.imshow(img1) . &lt;matplotlib.image.AxesImage at 0x7f3c2e4f8240&gt; . . Why is this Blue? . OpenCV represents RGB images as multi-dimensional NumPy arrays‚Ä¶but in reverse order! This means that images are actually represented in BGR order rather than RGB! | . How to change it? . Convert BGR $ rightarrow$ RGB | . plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)) . &lt;matplotlib.image.AxesImage at 0x7f3c2c0c2cf8&gt; . . plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)) . &lt;matplotlib.image.AxesImage at 0x7f3c2c089908&gt; . . img1.shape . (575, 1024, 3) . img2.shape . (798, 1200, 3) . We have a problem here, so let‚Äôs resize img2 using cv2.resize. . img2_resize = cv2.resize(img2, (img1.shape[1], img1.shape[0])) . plt.imshow(cv2.cvtColor(img2_resize, cv2.COLOR_BGR2RGB)) . &lt;matplotlib.image.AxesImage at 0x7f3c2c059898&gt; . . img2_resize.shape . (575, 1024, 3) . blended = cv2.addWeighted(img1, 0.3, img2_resize, 0.7, 0) . plt.imshow(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB)) . &lt;matplotlib.image.AxesImage at 0x7f3c1ff83d30&gt; . . Who needs photoshop now! Just kidding, but it is fun little way to do interesting things in OpenCV. We‚Äôll take a look at it more. . Bitwise operations . Next up we would try to extract the Google Logo from image img, resize it and put it on top of the blended image . # Finding the Region of Image for the logo that we already have! plt.imshow(logo) . &lt;matplotlib.image.AxesImage at 0x7f3c1ff4c1d0&gt; . . rows, cols, channels = logo.shape roi = blended[0:rows, 0:cols] #Putting it in the left hand side of the image . plt.imshow(roi) . &lt;matplotlib.image.AxesImage at 0x7f3c1ff1a438&gt; . . # Convert it to color first logo = cv2.cvtColor(logo, cv2.COLOR_BGR2RGB) . plt.imshow(logo) . &lt;matplotlib.image.AxesImage at 0x7f3c1fee7ef0&gt; . . logo2gray = cv2.cvtColor(logo,cv2.COLOR_BGR2GRAY) . plt.imshow((logo2gray), cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1feba828&gt; . . Doesn‚Äôt give anything, well threshold are hard to determine manually . # initialize the list of threshold methods methods = [ (&quot;THRESH_BINARY&quot;, cv2.THRESH_BINARY), (&quot;THRESH_BINARY_INV&quot;, cv2.THRESH_BINARY_INV), (&quot;THRESH_TRUNC&quot;, cv2.THRESH_TRUNC), (&quot;THRESH_TOZERO&quot;, cv2.THRESH_TOZERO), (&quot;THRESH_TOZERO_INV&quot;, cv2.THRESH_TOZERO_INV)] # loop over the threshold methods for (threshName, threshMethod) in methods: # threshold the image and show it (T, thresh) = cv2.threshold(logo2gray, 10, 255, threshMethod) cv2.imshow(threshName, thresh) cv2.waitKey(0) . If you see, the THRESH_TOZERO is way better so we‚Äôll use that. . #Create its mask # cv2.threshold(src, thresh, maxval, type) ret, mask = cv2.threshold(logo2gray, 200, 255, cv2.THRESH_BINARY_INV) print(ret) print(&quot;--&quot;) print(plt.imshow(mask)) . 200.0 -- AxesImage(54,36;334.8x217.44) . . mask_inv = cv2.bitwise_not(mask) print(plt.imshow(mask)) . AxesImage(54,36;334.8x217.44) . . # Blackout the area of logo in ROI logo_bg = cv2.bitwise_and(roi, roi, mask=mask_inv) . logo_b = cv2.bitwise_and(roi, roi, mask=mask) . plt.imshow(logo_bg) . &lt;matplotlib.image.AxesImage at 0x7f3c1fdaf160&gt; . . plt.imshow(logo_b) . &lt;matplotlib.image.AxesImage at 0x7f3c1fd7b9e8&gt; . . # Take only region of logo from logo image. img2_fg = cv2.bitwise_and(logo_bg,logo_bg,mask = mask) . img2_fg.shape . (200, 400, 3) . plt.imshow(img2_fg) . &lt;matplotlib.image.AxesImage at 0x7f3c1fcce208&gt; . . final = cv2.add(img2_fg, logo_bg) plt.imshow(cv2.cvtColor(final, cv2.COLOR_BGR2RGB)) . &lt;matplotlib.image.AxesImage at 0x7f3c1fc9dcc0&gt; . . Adding the logo to our blended image (inside the ROI) . blended[0:rows, 0:cols] = final . plt.imshow(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB)) . &lt;matplotlib.image.AxesImage at 0x7f3c1fc6f3c8&gt; . . Image Processing . Changing Colorspaces . Convert images from one color space to another, BGR $ leftrightarrow$ Gray or BGR $ leftrightarrow$ HSV. Useful, when extracting a colored image from a video feed or image. . Reads: . HSV &amp; HSL | Why HSV for object detection | ! curl &quot;https://fsmedia.imgix.net/9f/50/d1/5b/6c4e/419a/800e/e942305776e7/imagenes-de-power-rangers-furia-animaljpg.jpeg&quot; &gt; power_rangers.jpg . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 339k 100 339k 0 0 225k 0 0:00:01 0:00:01 --:--:-- 285k . color_sample = cv2.imread(&#39;power_rangers.jpg&#39;) plt.imshow(cv2.cvtColor(color_sample, cv2.COLOR_BGR2RGB)) . &lt;matplotlib.image.AxesImage at 0x7f3c1fe27fd0&gt; . . What we have to do here is to detect the Red Power Ranger. To detect the color, we need to define the colors in HSV (define boundary values). . boundaries = [([0, 0, 50], [30, 40, 255]), ([86, 31, 4], [220, 88, 50]), ([25, 146, 190], [62, 174, 250]), ([103, 86, 65], [145, 133, 128])] . boundaries[0][0] . [0, 0, 50] . # We need to convert the boundaries to numpy arrays lower = np.array(boundaries[0][0], dtype=&#39;uint8&#39;) upper = np.array(boundaries[0][1], dtype=&#39;uint8&#39;) . # We&#39;ll find the mask mask = cv2.inRange(color_sample, lower, upper) . plt.imshow(mask) . &lt;matplotlib.image.AxesImage at 0x7f3c1fe65b70&gt; . . output = cv2.bitwise_and(color_sample, color_sample, mask = mask) . plt.imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB)) . &lt;matplotlib.image.AxesImage at 0x7f3c1fc35cf8&gt; . . After the red ranger, let‚Äôs try to find out the blue ranger. . blue_lower = np.array([86, 20, 4], dtype=&#39;uint8&#39;) blue_upper = np.array([255, 120, 120], dtype=&#39;uint8&#39;) . mask_blue = cv2.inRange(color_sample, blue_lower, blue_upper) . plt.imshow(mask_blue) . &lt;matplotlib.image.AxesImage at 0x7f3c1fb84588&gt; . . output_blue = cv2.bitwise_and(color_sample, color_sample, mask=mask_blue) . plt.imshow(cv2.cvtColor(output_blue, cv2.COLOR_BGR2RGB)) . &lt;matplotlib.image.AxesImage at 0x7f3c1fb6e0f0&gt; . . Image Thresholding . In the 1st example (the Arsenal blending), we saw how image can be thresholded manually. In this we‚Äôll look at other means of thresholding. . Adaptive Thresholding | . Using a global value as a threshold doesn‚Äôt cut out for real world applications. There are various factors that we need to look in and understand before understanding things. . The algorithm calculate the threshold for a small regions of the image. So we get different thresholds for different regions of the same image and it gives us better results for images with varying illumination. . It has three ‚Äòspecial‚Äô input params and only one output argument. . Adaptive Method - It decides how thresholding value is calculated. cv2.ADAPTIVE_THRESH_MEAN_C : threshold value is the mean of neighbourhood area. | cv2.ADAPTIVE_THRESH_GAUSSIAN_C : threshold value is the weighted sum of neighbourhood values where weights are a gaussian window. | . | Block Size - It decides the size of neighbourhood area. | C - It is just a constant which is subtracted from the mean or weighted mean calculated. | . Let‚Äôs look at an example: . !curl &quot;https://upload.wikimedia.org/wikipedia/commons/0/0b/ReceiptSwiss.jpg&quot; &gt; receipt.jpg . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 940k 100 940k 0 0 244k 0 0:00:03 0:00:03 --:--:-- 252k . receipt = cv2.imread(&#39;receipt.jpg&#39;) . plt.rcParams[&quot;figure.figsize&quot;] = (60,10) plt.imshow(receipt) . &lt;matplotlib.image.AxesImage at 0x7f3c1fadda20&gt; . . receipt = cv2.medianBlur(receipt, 5) . receipt = cv2.cvtColor(receipt, cv2.COLOR_BGR2GRAY) . # Using gloal threshold ret, th1 = cv2.threshold(receipt, 127, 255, cv2.THRESH_BINARY) . th2 = cv2.adaptiveThreshold(receipt, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,115,2) . th3 = cv2.adaptiveThreshold(receipt,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,115,2) . titles = [&#39;Original Image&#39;, &#39;Global Thresholding (v = 127)&#39;, &#39;Adaptive Mean Thresholding&#39;, &#39;Adaptive Gaussian Thresholding&#39;] . images = [receipt, th1, th2, th3] . plt.rcParams[&quot;figure.figsize&quot;] = (60,10) plt.imshow(th1, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1f9af4e0&gt; . . plt.rcParams[&quot;figure.figsize&quot;] = (60,10) plt.imshow(th2, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1f918be0&gt; . . plt.rcParams[&quot;figure.figsize&quot;] = (60,10) plt.imshow(th3, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1f8871d0&gt; . . Geometric Transformation of Images . Scaling | . Scaling is just resizing of the image. OpenCV comes with a function cv2.resize() for this purpose. The size of the image can be specified manually, or you can specify the scaling factor. . !curl &quot;http://vignette4.wikia.nocookie.net/dragonball/images/4/4b/VegetaItsOver9000-02.png/revision/latest?cb=20100724145819&quot; &gt; vegeta.png . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 310k 100 310k 0 0 99k 0 0:00:03 0:00:03 --:--:-- 129k . vegeta = cv2.imread(&#39;vegeta.png&#39;) . vegeta = cv2.cvtColor(vegeta, cv2.COLOR_BGR2RGB) . plt.rcParams[&quot;figure.figsize&quot;] = (17,8) plt.imshow(vegeta) . &lt;matplotlib.image.AxesImage at 0x7f3c1f86b3c8&gt; . . Vegeta is angry coz Goku‚Äôs power levels are OVER 9000! and also the image is too big. Let‚Äôs do transform to resize him. . # Image shape:: vegeta.shape . (480, 640, 3) . We‚Äôll reduce the dimensions to 200x300, keeping the channels same. . re1 = cv2.resize(vegeta, (200, 100), interpolation=cv2.INTER_CUBIC) . plt.imshow(re1) . &lt;matplotlib.image.AxesImage at 0x7f3c1f7d2630&gt; . . re1.shape . (100, 200, 3) . re2 = cv2.resize(vegeta, (200, 100), interpolation=cv2.INTER_AREA) plt.imshow(re1) . &lt;matplotlib.image.AxesImage at 0x7f3c1f741748&gt; . . re2 = cv2.resize(vegeta, (200, 100), interpolation=cv2.INTER_LINEAR) plt.imshow(re1) . &lt;matplotlib.image.AxesImage at 0x7f3c1f72f4e0&gt; . . Looks more scary now though! . Translation . Translation is the shifting of object‚Äôs location. If you know the shift in (x,y) direction, let it be $(t_{x},t_{y})$, you can create the transformation matrix $ textbf{M}$ as follows: . $M = begin{bmatrix} 1 &amp; 0 &amp; t_x 0 &amp; 1 &amp; t_y end{bmatrix}$ . M = np.float32([[1,0,100],[0,1,160]]) . final_form = cv2.warpAffine(vegeta, M, (vegeta.shape[0], vegeta.shape[1])) . plt.imshow(final_form) . &lt;matplotlib.image.AxesImage at 0x7f3c1f0e8048&gt; . . Affine Transformation . In affine transformation, all parallel lines in the original image will still be parallel in the output image. . Perspective Transformation . A great read would be - this blog. Explains how perspective transformation works. We have seen Perspective transformation used in document scanners on our phones, neat application. . Smoothing Images . To blur images using low pass filters | Applying custom made filters to images (2D Convolution) | . 2D Convolution or Image Filtering . cv2.filter2D() to convolve an image! . Definition of convolution: coil or twist. . Mathematically, convolution is a mathematical operation on two functions (f and g); it produces a third function, that is typically viewed as a modified version of one of the original functions, giving the integral of the pointwise multiplication of the two functions as a function of the amount that one of the original functions is translated. . ¬† ¬† . In Image processing, we would see how convolution works! . Consider the Google Logo: . plt.rcParams[&quot;figure.figsize&quot;] = (10,3) plt.imshow(logo) . &lt;matplotlib.image.AxesImage at 0x7f3c1f0507f0&gt; . . We always need to define a kernel, it is a small tool that moves through the entire image so that we get the required transformed image. Read this Setosa.io blog that explains kernels in an intuitive way . kernel = np.ones((5,5), np.float32)/25 print(kernel) . [[ 0.04 0.04 0.04 0.04 0.04] [ 0.04 0.04 0.04 0.04 0.04] [ 0.04 0.04 0.04 0.04 0.04] [ 0.04 0.04 0.04 0.04 0.04] [ 0.04 0.04 0.04 0.04 0.04]] . # Applying the Kernel over the logo, simple box blur logo_blur = cv2.filter2D(logo, -1, kernel) . plt.rcParams[&quot;figure.figsize&quot;] = (10,3) plt.imshow(logo_blur) . &lt;matplotlib.image.AxesImage at 0x7f3c1efca198&gt; . . Image Blurring . This is useful to remove the noise. Removes the high frequency content(noise, edges) from images, resulting in edges being blurred when filter is applied. . There are various types of blurring techniques. . Averaging: . Done by taking the average of all the pixels under kernel area and replaces the central element with this average. This is done by the function cv2.blur() or cv2.boxFilter(). . | . logo_avg_blur = cv2.blur(logo, (6,6)) plt.rcParams[&quot;figure.figsize&quot;] = (10,3) plt.imshow(logo_avg_blur) . &lt;matplotlib.image.AxesImage at 0x7f3c1efbd7b8&gt; . . Gaussian Blur: . Below is a Gaussian Kernel (source) . | . logo_gauss = cv2.GaussianBlur(logo, (5,5), 0) plt.rcParams[&quot;figure.figsize&quot;] = (10,3) plt.imshow(logo_gauss) . &lt;matplotlib.image.AxesImage at 0x7f3c1ef35198&gt; . . Median Filtering: . Computes the median of all the pixels under the kernel window &amp; the central pixel is replaced by the median value. Highly effective in removing salt-and-pepper noise. . | . We‚Äôll first download an image having salt-and-pepper noise: . !curl &quot;https://upload.wikimedia.org/wikipedia/commons/f/f4/Noise_salt_and_pepper.png&quot; &gt; sp.png . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 82829 100 82829 0 0 39024 0 0:00:02 0:00:02 --:--:-- 51703 . sp = cv2.imread(&#39;sp.png&#39;) sp_median = cv2.medianBlur(sp,5) plt.rcParams[&quot;figure.figsize&quot;] = (20,7) plt.subplot(1,2,1),plt.imshow(sp),plt.title(&#39;Salt &amp; Pepper&#39;) plt.xticks([]), plt.yticks([]) plt.subplot(1,2,2),plt.imshow(sp_median),plt.title(&#39;Processed&#39;) plt.xticks([]), plt.yticks([]) plt.tight_layout() plt.show() . . Bilateral Filtering: . The previous 2 approaches remove the noise as well as the edges. Bilateral Filtering does the noise removal, but it keeps the edges. We‚Äôll compare the three images (with noise, Gaussian &amp; Bilateral) side by side, to check the differences. . | . Downloading the image: . !curl &quot;https://upload.wikimedia.org/wikipedia/commons/d/d2/512x512-Gaussian-Noise.jpg&quot; &gt; gauss.jpg . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 94314 100 94314 0 0 50518 0 0:00:01 0:00:01 --:--:-- 65541 . gauss = cv2.imread(&#39;gauss.jpg&#39;) gauss_gauss = cv2.GaussianBlur(gauss, (5,5), 0) #bilateralFilter(input array (image), output array, diameter of pixel neighbour hood, sigmaColor, sigmaSpace) gauss_bilateral = cv2.bilateralFilter(gauss, 9, 75, 75) . plt.rcParams[&quot;figure.figsize&quot;] = (15,6) plt.subplot(1,3,1), plt.imshow(gauss),plt.title(&#39;Original with noise&#39;) plt.xticks([]), plt.yticks([]) plt.subplot(1,3,2), plt.imshow(gauss_gauss),plt.title(&#39;Gaussian Filter&#39;) plt.xticks([]), plt.yticks([]) plt.subplot(1,3,3), plt.imshow(gauss_bilateral),plt.title(&#39;Bilateral Filter&#39;) plt.xticks([]), plt.yticks([]) plt.show() . . As you ca see, the Bilateral Filter doesn‚Äôt have hazy edges like the Gaussian. . Morphological Transformation . Morphological Transformations are basically playing with the shape of the original image, manipulating the internals of the image. There are 2 major operations: Erosion &amp; Dilation. . Erosion: . Similar to the erosion of banks of a river, we try to erode away boundaries of the foreground object. . . | . The kernel slides through the image (as in 2D convolution). A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero). It is advisable to have the foreground as white (for reasons above). . !curl &quot;http://pad1.whstatic.com/images/thumb/e/ef/Divide-Double-Digits-Step-9-Version-5.jpg/aid281771-v4-728px-Divide-Double-Digits-Step-9-Version-5.jpg&quot; &gt; digits.png . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 46846 100 46846 0 0 48692 0 --:--:-- --:--:-- --:--:-- 50644 . digits = cv2.imread(&#39;digits.png&#39;) plt.imshow(digits) . &lt;matplotlib.image.AxesImage at 0x7f3c1ee0c748&gt; . . digits = cv2.cvtColor(digits, cv2.COLOR_BGR2GRAY) plt.imshow(digits, cmap=plt.get_cmap(&#39;gray&#39;)) . &lt;matplotlib.image.AxesImage at 0x7f3c1ed45898&gt; . . ret, mask = cv2.threshold(digits, 200, 255, cv2.THRESH_BINARY_INV) plt.imshow(mask, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1ee77fd0&gt; . . kernel = np.ones((5,5), np.uint8) eroded = cv2.erode(mask, kernel, iterations=1) plt.imshow(eroded, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1edce4a8&gt; . . Dilation: . You just make it fat! Remember the phrase, ‚ÄúDilation of Pupil‚Äù. . . | . kernel = np.ones((5,5), np.uint8) dilated = cv2.dilate(mask, kernel, iterations=1) plt.imshow(dilated, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1ecf5cc0&gt; . . Opening &amp; Closing: . Opening is just another name of erosion followed by dilation. It is useful in removing noise. . Closing is reverse of Opening, Dilation followed by Erosion. It is useful in closing small holes inside the foreground objects, or small black points on the object. . How do we remove noise? If we have white holes in the object as below: . | . ret, mask = cv2.threshold(sp, 100, 255, cv2.THRESH_BINARY) plt.imshow(mask, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1ec670b8&gt; . . We‚Äôll apply Opening to the image. . opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel) plt.imshow(opening, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1ebdb4e0&gt; . . As we can see above, there were still black dots inside the image that weren‚Äôt taken care of. We‚Äôll do that using Closing . closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel) plt.imshow(closing, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1eb4d940&gt; . . The final outcome is disastrous, but you get the point right! Next in line is Morphological Gradient. . Morphological Gradient . Difference between dilation &amp; erosion of an image. . | . ret, mask = cv2.threshold(digits, 200, 255, cv2.THRESH_BINARY_INV) kernel = np.ones((3,3), np.uint8) gradient = cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, kernel) plt.subplot(1,2,1), plt.imshow(mask, cmap=&#39;gray&#39;),plt.title(&#39;Original&#39;) plt.xticks([]), plt.yticks([]) plt.subplot(1,2,2), plt.imshow(gradient, cmap=&#39;gray&#39;),plt.title(&#39;Morphological Gradient&#39;) plt.xticks([]), plt.yticks([]) plt.show() . . Image Gradients . Image gradients can be used to extract information from images. Gradient images are created from the original image (generally by convolving with a filter, one of the simplest being the Sobel filter) for this purpose. Each pixel of a gradient image measures the change in intensity of that same point in the original image, in a given direction. To get the full range of direction, gradient images in the x and y directions are computed. . One of the most common uses is in edge detection. One example of an edge detection algorithm that uses gradients is the Canny edge detector. . Consider the image, receipt, which we used previously. . plt.rcParams[&quot;figure.figsize&quot;] = (20,10) plt.imshow(receipt, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1ea76c18&gt; . . 1. Sobel &amp; Scharr Derivatives . $ textbf{Sobel Operators = Gaussian Smooting + Differentiation Operator}$ . In the image at the start of this topic, we can see the directions. These directions are specified by the yorder &amp; xorder (vertical &amp; horizontal respectively). . Size of the kernel, ksize can be specified (any value, generally if ksize=5 the kernel is 5x5). . If ksize=-1, a Scharr filter is used (?) . 2. Laplacian Derivatives . Laplacian of the image is given by: $ Delta src = frac{ partial ^2{src}}{ partial x^2} + frac{ partial ^2{src}}{ partial y^2}$ . Each derivative is found using Sobel derivatives. . Reading . plt.rcParams[&quot;figure.figsize&quot;] = (20,10) plt.imshow(receipt,cmap = &#39;gray&#39;) plt.title(&#39;Original&#39;), plt.xticks([]), plt.yticks([]) . (&lt;matplotlib.text.Text at 0x7f3c1e9b8ba8&gt;, ([], &lt;a list of 0 Text xticklabel objects&gt;), ([], &lt;a list of 0 Text yticklabel objects&gt;)) . . sobelx = cv2.Sobel(receipt, cv2.CV_8U, 1, 0, ksize=3) plt.rcParams[&quot;figure.figsize&quot;] = (20,10) plt.imshow(sobelx, cmap=&#39;gray&#39;) plt.show() . . sobely = cv2.Sobel(receipt, cv2.CV_16U, 0, 1, ksize=5) plt.rcParams[&quot;figure.figsize&quot;] = (20,10) plt.imshow(sobely, cmap=&#39;gray&#39;) plt.show() . . scharrx = cv2.Sobel(receipt, cv2.CV_16U, 1, 0, ksize=-1) plt.rcParams[&quot;figure.figsize&quot;] = (20,10) plt.imshow(scharrx, cmap=&#39;gray&#39;) plt.show() . . scharry = cv2.Sobel(receipt, cv2.CV_16U, 0, 1, ksize=-1) plt.rcParams[&quot;figure.figsize&quot;] = (20,10) plt.imshow(scharry, cmap=&#39;gray&#39;) plt.show() . . laplacian = cv2.Laplacian(receipt, cv2.CV_8U) plt.rcParams[&quot;figure.figsize&quot;] = (20,10) plt.imshow(laplacian, cmap=&#39;gray&#39;) plt.show() . . Canny Edge Detection . Canny Edge Detection is a popular edge detection algorithm. It was developed by John F. Canny in 1986. It is a multi-stage algorithm. . It goes through the following stages: . Noise Reduction: . Edge detection, as in the previous few topics, we know that it is succeptible to noise. Canny Edge detector takes care of that. . | Finding Intensity Gradient of the Image. . The image is then passed through Sobel filter, both in horizontal &amp; vertical direction. . | Non-maximum suppression . (Difficult to explain) . | Hysteresis Thresholding . This stage decides which are edges and which are not. This also removes small pixel noises on the assumption that the edges are along the lines. . | edge_receipt = cv2.Canny(receipt, 150, 300) plt.imshow(edge_receipt, cmap=&#39;gray&#39;) plt.show() . . Probably, not a great image to do edge detection. Let‚Äôs look at detecting road lanes. . !curl &quot;http://www.richmondregional.org/images/monthly_flyer/September_2010_Graphics/DTE_ORT_lanes.jpg&quot; &gt; road_lanes.jpg . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 496k 100 496k 0 0 78521 0 0:00:06 0:00:06 --:--:-- 127k . road_lanes = cv2.imread(&#39;road_lanes.jpg&#39;) . road_lanes = cv2.cvtColor(road_lanes, cv2.COLOR_BGR2GRAY) plt.imshow(road_lanes, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1e88a6a0&gt; . . road_canny = cv2.Canny(road_lanes, 100,200) plt.rcParams[&#39;figure.figsize&#39;] = (15,7) plt.imshow(road_canny, cmap=&#39;gray&#39;) plt.show() . . Contours . Contours by definition: An outline representing or bounding the shape or form of something. . In the above road lane detection, we got the threholded image. To create a boundary around it, we need the help of contours. More reading . Berkley Computer Vision Group . !curl &quot;https://www.echalk.co.uk/amusements/Games/Tetrominoes/shareIcons/shareIcon.jpg&quot; &gt; tetris.jpg . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 30401 100 30401 0 0 17879 0 0:00:01 0:00:01 --:--:-- 19740 . tetris = cv2.imread(&#39;tetris.jpg&#39;) tetris_gray = cv2.cvtColor(tetris, cv2.COLOR_BGR2GRAY) ret, mask = cv2.threshold(tetris_gray, 200, 255, cv2.THRESH_BINARY_INV) plt.imshow(mask, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1eb1a470&gt; . . We‚Äôll get the blue blocks, for that we need to use cv2.inRange() . tetris_color = cv2.cvtColor(tetris, cv2.COLOR_BGR2RGB) . blue_lower = np.array([50, 0, 0], dtype=&#39;uint8&#39;) blue_upper = np.array([255, 0, 0], dtype=&#39;uint8&#39;) . mask_blue = cv2.inRange(tetris_color, blue_lower, blue_upper) . plt.imshow(mask_blue) . &lt;matplotlib.image.AxesImage at 0x7f3c1e790710&gt; . . output = cv2.bitwise_and(tetris_color, tetris_color, mask = mask_blue) . plt.imshow(output) . &lt;matplotlib.image.AxesImage at 0x7f3c1e779e80&gt; . . output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB) plt.imshow(output) . &lt;matplotlib.image.AxesImage at 0x7f3c1e6e84e0&gt; . . output_gray = cv2.cvtColor(output, cv2.COLOR_RGB2GRAY) plt.imshow(output_gray, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1e651b00&gt; . . _, contours, hierarchy = cv2.findContours(output_gray.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) . cont_digits = cv2.drawContours(output.copy(), contours, -1, (0, 255, 0), 3) . plt.imshow(cont_digits, cmap=&#39;gray&#39;) plt.show() . . Contour Features . In statistics, Moments are the quantitative measures to define data points. The moments defined are: . Total Probability (Zeroth moment) | Mean (1st moment) | Variance (2nd moment) | Skewness (3rd moment) | Kurtosis (4th moment) | . Image moments helps us to create features: center of mass of object, area of the object. . We already have to contours from the above image, calculating the moments. . !curl &quot;http://vignette3.wikia.nocookie.net/marvel_dc/images/d/df/Flash_Logo_01.png/revision/latest?cb=20140529051349&quot; &gt; flash.png . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 143k 100 143k 0 0 148k 0 --:--:-- --:--:-- --:--:-- 161k . flash = cv2.imread(&#39;flash.png&#39;) flash = cv2.cvtColor(flash, cv2.COLOR_BGR2RGB) plt.imshow(flash) . &lt;matplotlib.image.AxesImage at 0x7f3c1e5ad7b8&gt; . . flash_gray = cv2.cvtColor(flash, cv2.COLOR_RGB2GRAY) ret, mask = cv2.threshold(flash_gray, 150, 255, cv2.THRESH_BINARY_INV) plt.imshow(mask, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1e526080&gt; . . _, contours, hierarchy = cv2.findContours(mask.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) . cont_flash = cv2.drawContours(flash.copy(), contours[6], -1, (0, 255, 0), 3) . plt.imshow(cont_flash, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1e49a5c0&gt; . . NOTE: The official documentation as well as the popular blogs do not mention this regarding the contours. You need to find the specific contours for the shape in the image. So our flash contour would have a separate set of values here, likewise the circle inside which the flash sign is. . This is true everywhere, there will be situations where there are more than 100 contour values. God bless us then! . len(contours) . 10 . cnt = contours[6] moments = cv2.moments(cnt) print(moments) . {&#39;nu11&#39;: -0.1907517670263885, &#39;nu30&#39;: -0.016394871693779282, &#39;nu03&#39;: 0.01208933681388529, &#39;mu30&#39;: -172121780.97688293, &#39;m01&#39;: 2010266.8333333333, &#39;nu21&#39;: 0.020979023957747672, &#39;mu02&#39;: 34511693.70050317, &#39;nu20&#39;: 0.1388066996783884, &#39;mu20&#39;: 14431539.936564565, &#39;mu21&#39;: 220248565.17384815, &#39;m10&#39;: 2147855.6666666665, &#39;nu12&#39;: -0.02132463374655408, &#39;m21&#39;: 83909645927.7, &#39;mu12&#39;: -223876954.18984604, &#39;mu11&#39;: -19832196.50196892, &#39;m12&#39;: 82711294309.23334, &#39;m00&#39;: 10196.5, &#39;m02&#39;: 430841095.0833333, &#39;m30&#39;: 104252150772.20001, &#39;m11&#39;: 403623205.7916666, &#39;mu03&#39;: 126920065.13383484, &#39;nu02&#39;: 0.33194339092953673, &#39;m20&#39;: 466869529.9166666, &#39;m03&#39;: 98676519466.85} . #To find centroid: cx = int(moments[&#39;m10&#39;]/moments[&#39;m00&#39;]) cy = int(moments[&#39;m01&#39;]/moments[&#39;m00&#39;]) . print(&quot;The centroid is ({},{})&quot;.format(cx,cy)) . The centroid is (210,197) . print(&quot;The contour area is {}&quot;.format(moments[&#39;m00&#39;])) . The contour area is 10196.5 . We can find the contour area using cv2.contourArea() . print(&quot;The contour area is {}&quot;.format(cv2.contourArea(cnt))) . The contour area is 10196.5 . # Finding the contour perimeter perimeter = cv2.arcLength(cnt, True) print(perimeter) . 947.6336801052094 . Contour Approximation | . approx = cv2.approxPolyDP(cnt, perimeter, True) print(approx) . [[[301 52]]] . Bounding Rectangles . Selecting the bounding box only for the flash! . | . x, y, w, h = cv2.boundingRect(cnt) rect = cv2.rectangle(flash.copy(), (x,y), (x+w, y+h), (0,255,0), 5) plt.imshow(rect) . &lt;matplotlib.image.AxesImage at 0x7f3c1e41c6d8&gt; . . rect = cv2.minAreaRect(cnt) box = cv2.boxPoints(rect) box = np.int0(box) rect_draw = cv2.drawContours(flash.copy(), [box], 0, (255,0,0), 5) . plt.imshow(rect_draw, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1e389cf8&gt; . . Minimum Enclosing Circle . Cover the ‚Äòflash‚Äô sign using a circle. . | . (x, y), radius = cv2.minEnclosingCircle(cnt) center = (int(x), int(y)) radius = int(radius) circle_draw = cv2.circle(flash.copy(), center, radius, (0,255,0), 4) plt.imshow(circle_draw) . &lt;matplotlib.image.AxesImage at 0x7f3c1e308828&gt; . . Fitting an Ellipse . To fit an ellipse to the flash sign. . | . ellipse = cv2.fitEllipse(cnt) draw_ellipse = cv2.ellipse(flash.copy(), ellipse, (0,255,0), 4) plt.imshow(draw_ellipse) . &lt;matplotlib.image.AxesImage at 0x7f3c1e677048&gt; . . Histograms . A histogram represents the distribution of colors in an image. It can be visualized as a graph (or plot) that gives a high-level intuition of the intensity (pixel value) distribution. We are going to assume a RGB color space in this example, so these pixel values will be in the range of 0 to 255. . By looking at the histogram of an image, you get intuition about contrast, brightness, intensity distribution etc of that image. . !curl &quot;https://media1.britannica.com/eb-media/54/155954-004-4BF4BBF7.jpg&quot; &gt; everest.jpg . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 29947 100 29947 0 0 59170 0 --:--:-- --:--:-- --:--:-- 117k . everest = cv2.imread(&#39;everest.jpg&#39;) everest_gray = cv2.cvtColor(everest, cv2.COLOR_BGR2GRAY) plt.imshow(everest_gray, cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1eb7f630&gt; . . Plot histograms using just matplotlib | . plt.hist(everest_gray.ravel(), 265, [0,256]) plt.show() . . color = (&#39;b&#39;, &#39;g&#39;, &#39;r&#39;) for i, col in enumerate(color): histr = cv2.calcHist([everest], [i], None, [256], [0,256]) plt.plot(histr, color=col) plt.xlim([0,256]) plt.show() . . Multi-Dimensional Histograms | . hsv = cv2.cvtColor(everest, cv2.COLOR_BGR2HSV) plt.imshow(hsv) . &lt;matplotlib.image.AxesImage at 0x7f3c1df17e48&gt; . . # calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]]) hist = cv2.calcHist([hsv], [0,1], None, [180, 256], [0, 180, 0, 256]) . plt.imshow(hist, interpolation=&#39;nearest&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3c1df033c8&gt; . . Applications of histograms still feels as something very obscure at this point of time. Let‚Äôs continue the discussion after I understand things. . This should get you started off with using OpenCV at a very primary level. Even I‚Äôve not mastered it, still to cover a lot of ground. Next part would be using all the learnings to create an application or maybe a Kaggle competition dataset for practice. .",
            "url": "https://pratos.github.io/shodh/2017/06/13/opencv-code-snippets-intro.html",
            "relUrl": "/2017/06/13/opencv-code-snippets-intro.html",
            "date": " ‚Ä¢ Jun 13, 2017"
        }
        
    
  
    
        ,"post4": {
            "title": "Docker for Data Science - Part 1",
            "content": "Source: Docker Homepage . The situation . . As Data Scientist/Data Analysts/Data Science enthusiasts, we are by far a messier version of our Software Engineering counter parts. We like quick, dirty solutions. Code base that sometimes puts a double burst cheese pizza to shame (yum though!). . We like to experiment, change things on the fly and get the results out as soon as possible‚Ä¶coz deadlines shakes head. All this adds to the mess that already is - dependencies, obscure packages and platform dependent issues. To replicate the same experiment takes more than just writing random.seed(4), and there comes the classic problems: . ‚ÄúOkay! But that ran on my system‚Äù . ‚ÄúI have sent every code script, data and other things. Strange I haven‚Äôt missed any.‚Äù . ‚ÄúToo lazy to install everything from scratch, hate Linux/Windows/Mac‚Äù . ‚ÄúCan‚Äôt install the package that you used, can you help me out?‚Äù . What if I told you, as Data Scientist one can easily get all this sorted? Docker is the answer! . There‚Äôll be a section of readers who would be thinking, ‚ÄúDocker is nuts! Only DevOps folks know it in and out!‚Äù. True in some respects, but if there‚Äôs a way to standardize our Data Science Workflow and be productive then why not try it out. Knowing just small bit of Docker would be enough as a starting point. . What is Docker? . . According to Docker‚Äôs official website: . Docker is the world‚Äôs leading software container platform. Developers use Docker to eliminate ‚Äúworks on my machine‚Äù problems when collaborating on code with co-workers. Operators use Docker to run and manage apps side-by-side in isolated containers to get better compute density. Enterprises use Docker to build agile software delivery pipelines to ship new features faster, more securely and with confidence for both Linux and Windows Server apps. . Docker provides us an isolated container, where we can add all the things that we need to for our experiment to run. We could also create a full fledged web application that can be used as a production grade. So right from experiments to production applications, Docker provides a good means to get our Data Science applications out in the real world. . To learn Docker, we need to understand the terminologies and tools on offer and what we can do with it. . Docker Terminology: . Docker Containers: Small user-level virtualization (isolation) that helps you install, build and run your code/workflow. All the code would be continuosly running in these containers. | Docker Images: An image is an inert, immutable, file that‚Äôs essentially a snapshot of a container. These are your actual committed containers (ones that have the process running, data stored, ports exposed to be used). Docker images are essentially the stored instances that you can (actually move around). | Dockerfile: It is a YAML (almost) based file from which Docker creates an image. It can be thought of as an automated script that has all the steps you want to execute. | You could be a Data Science enthusiasts who can share his code without documenting any single thing, Dockerfile (more on this later) is self-documenting. All you have to do is create a Docker image, upload it on DockerHub and share it with the world! . A good resource to know more about Docker and Containerization technology as a whole read this blog . In this blog post, we‚Äôll tackle very narrow problems of Starting off with pre-built Docker images and Environment packaging. . Docker installation . . All the examples here are generic, except for the installation of Docker. The official Docker installation documents for Windows and Mac are pretty straight forward. You can start off Docker installation using this DigitalOcean blog post. . (Tip: For any Linux distro related installations, DigitalOcean articles are the real deal! Always search for them.) . Docker for instant gratification . . Getting the right tool to do things is hard and getting it installed on your system is a tough job sometimes. . Let‚Äôs take an example Python‚Äôs cryptography installation on your Windows system, unless you have the right Microsoft authorized C++ compiler the package won‚Äôt pip install. After ardorous, time sapping attempts you might get things running. In Ubuntu, installation is just a breeze. . Read my experiences in compiling TensorFlow Serving, that would give you a fair idea that setting up platform to do things, especially obscure things take time. . Docker solves this, DockerHub has a host of images uploaded by individuals and tech teams alike. Right from Hello World images to LISP images. . What do you need to do? Just docker pull &lt;username&gt;/&lt;image-name&gt;. It would download the image for you. Try out the following: . user@user:~$ docker pull hello-world Using default tag: latest latest: Pulling from library/hello-world 78445dd45222: Pull complete Digest: sha256:c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7 Status: Downloaded newer image for hello-world:latest . To run the docker image run command as below: . docker run hello-world . Should give you output: . Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://cloud.docker.com/ For more examples and ideas, visit: https://docs.docker.com/engine/userguide/ . Generally the docker files that you would use for Data Science purposes would be much complex with a variety of components to take care of: ports, volumes and many other things. . We‚Äôll look at how to run a full fledged Anaconda jupyter notebook that has all the components pre-installed. (An easier version of conda installation). . user@user:~$ docker pull continuumio/anaconda3 Using default tag: latest latest: Pulling from continuumio/anaconda3 8ad8b3f87b37: Pull complete 26e5bbd29116: Pull complete 26a23cde1ff7: Pull complete 0947a413f98b: Pull complete Digest: sha256:d04148529d340097c08677061e7d08f42e13a51dbdbf7488d92af0a65fd82973 Status: Downloaded newer image for continuumio/anaconda3:latest . To log in the docker container, we can run the command below: - docker run -i -t continuumio/anaconda3 /bin/bash . To run Jupyter notebook in a no-browser mode, run the command below: - docker run -i -t -p 8888:8888 continuumio/anaconda3 /bin/bash -c &quot;/opt/conda/bin/conda install jupyter -y --quiet &amp;&amp; mkdir /opt/notebooks &amp;&amp; /opt/conda/bin/jupyter notebook --notebook-dir=/opt/notebooks --ip=&#39;*&#39; --port=8888 --no-browser&quot; . Here, let‚Äôs discuss what the 2nd command is doing: -i is running the image interactively. | -t is allocate a pseudo-TTY. | -p is connect/publish the container ports to host. Here localhost:8888 to 8888 of container. | Downloading jupyter and starting the notebooks in the --no-browser mode. | . | A few more that you should know are: -d is to run container in the background, without accidently closing it. | -v is to bind a volume to the container, useful when you want your notebooks and/or data to be reflected in the container from your local system. | . | . Go to the browser and run http://localhost:8888 to start running your experiments. Pretty nifty, if you want to start off easily using a ready-made docker container. . But, all of this doesn‚Äôt solve our main problem: Managing Environments. . Manage Environments and let others use that easily! . . For my daily work, I create virtual environments for each project using Anaconda distribution. It provides a very easy means to share code along with the environment.yml file that can be exported and used to install the entire environment. . There‚Äôs a good portability here, mind you, but still cross operating system (OS) installations may break. That‚Äôs where docker shines and with a great deal of eco-system components like docker-compose and docker-machine, it is easier than ever to get up and running with a tangible Data Science application. . Case: My colleague is fed up of sharing code with his friend, who isn‚Äôt exactly someone who would install obscure dependencies and actually run the code. We want to provide him ways to change and run the code with minimal headache. . . To start off, we‚Äôll be creating a Dockerfile. As explained above, Dockerfile would take care of setting up the image for you that includes downloading the base images, setting the maintainer name-id, installing the required ubuntu/debian programs, installing language dependencies and many more things. . We‚Äôll be creating a python3.5 based Docker image that would contain folders data and notebooks with ports 8888 exposed to connect to jupyter notebooks. . (Note: If any of the python modules can‚Äôt be installed via pip, it would be safe to write RUN commands to run them safely). . Create a folder with the tree structure as below: . . ‚îú‚îÄ‚îÄ data ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ readme.md ‚îú‚îÄ‚îÄ Dockerfile ‚îú‚îÄ‚îÄ notebook ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ readme.md ‚îú‚îÄ‚îÄ README.md ‚îî‚îÄ‚îÄ requirements.txt . We have the requirements.txt file as below: (Note: Do pip freeze &gt; requirements.txt to generate one for your conda environment ) . We‚Äôll start off with getting smaller components for our Dockerfile. . base image: . To make things simple, the base image that we‚Äôll use is the python:3.5.3-onbuild image. All we need is a requirements.txt file that would have all the python modules to be installed. To recap, it does the following: . Install python 3.5.3 | Pull in your source and put it in a conspicuous and runnable place. | Install your requirements.txt file. | . | . (Note: This would create a Debian container, not an Ubuntu one) . FROM python:3.5.3-onbuild . Updating the repository sources | . RUN apt-get update . Creating folders for data and notebooks | . RUN mkdir /data RUN mkdir /notebooks . Adding a temporary log folder in /tmp, using: | . RUN mkdir /tmp/tflearn_logs . Make those three folders as VOLUMES so that they can be accessible through the host machine too. . The main reason we have VOLUMES is that the data and notebooks can be shared separately, not through the images that we create (_Docker best practices states that it isn‚Äôt good to share data with Images, it could be done but avoided). . | . VOLUME [&quot;/data&quot;, &quot;/notebooks&quot;, &#39;/tmp/tflearn_logs&#39;] . Sometimes we might have installations like curl or cron that aren‚Äôt exactly in our base image. We‚Äôll RUN the installations as below: . RUN apt-get install cron -yqq curl . We‚Äôll expose the port: Other for Jupyter: 8888 | . | . # jupyter EXPOSE 8888 . We‚Äôll have to make an arrangement somehow to start the jupyter notebook as we run our image. For that, we‚Äôll use CMD to run our commands: | . CMD jupyter notebook --no-browser --ip=0.0.0.0 --allow-root --NotebookApp.token=&#39;demo&#39; . Finally, we have our Dockerfile as below: . We need to build the docker image by running the following command: . (sudo) docker -t build &lt;image-name&gt; . A simple inspection (below), would give you the statistics for the image generated: . user@user:~/docker-demo$ sudo docker images REPOSITORY TAG IMAGE ID CREATED SIZE demoimage latest 9d556dd63886 9 minutes ago 1.37 GB . Now the real test comes in, we need to test it by running the image and checking whether our volumes work or not! . Follow the commands below: . sudo docker run -d -v ~/docker-demo/notebooks:/notebooks -v ~/docker-demo/data:/data -v ~/docker-demo/logs:/tmp/tflearn_logs -p 8888:8888 -i demoimage . If you do a sudo docker ps, you would get the following output: . CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES fadf5e0646d5 demoimage &quot;/bin/sh -c &#39;tenso...&quot; 9 seconds ago Up 8 seconds 0.0.0.0:6006-&gt;6006/tcp, 0.0.0.0:8888-&gt;8888/tcp clever_payne . So we are all set to test the docker image: . Fire up the http://localhost:8888 to get the jupyter notebook. | . The container and host folders would be synced and persisted, no need to worry about losing the notebook,data and logs. . The last step would be saving this image to DockerHub as a public image or in a private repository to use it later. . # Login to DockerHub (_Note: You need to create your DockerHub account first_) sudo docker login . Once login is succeeded, we need to tag the image and then push the image: . sudo docker tag &lt;image-name&gt; &lt;login-id&gt;/&lt;image-name&gt; sudo docker push &lt;login-id&gt;/&lt;image-name&gt; . e.g. . sudo docker tag demoimage pratos/demoimage | sudo docker push pratos/demoimage | . So here it is, your very own docker image. My colleague would be happy to see this, like him even you could do more with docker images. Do try this out. . We would be looking at a few more things that Docker offers in the next post. To all the DevOps folks do provide feedback to this post and share it with all of us. . Sources: . For more indepth and simple understanding on how to write a Dockerfile | Docker Documentation |",
            "url": "https://pratos.github.io/shodh/2017/04/24/docker-for-data-science-part-1.html",
            "relUrl": "/2017/04/24/docker-for-data-science-part-1.html",
            "date": " ‚Ä¢ Apr 24, 2017"
        }
        
    
  
    
        ,"post5": {
            "title": "Pandas Indexing & Selecting using iloc, loc and ix",
            "content": "In Pandas 19.02, the indexing follows the same paradigms as Numpy. There‚Äôs not much of a difference if a newbie starts to slice pandas Dataframe according to the numpy conventions. However, there comes a time when things take turn for the worse when he/she encounters the three musketeers: iloc, loc and ix. . Source: Frost Click: Three Musketeers . Here‚Äôs to the many hours that I spent pulling out my hair in understanding this lot. . We‚Äôll start with the basic definitions that Pandas documentation has to offer: . .loc is primarily label based, but may also be used with a boolean array. .loc will raise KeyError when the items are not found. . .iloc is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array. .iloc will raise IndexError if a requested indexer is out-of-bounds, except slice indexers which allow out-of-bounds indexing. (this conforms with python/numpy slice semantics). . .ix supports mixed integer and label based access. It is primarily label based, but will fall back to integer positional access unless the corresponding axis is of integer type. .ix is the most general and will support any of the inputs in .loc and .iloc. .ix also supports floating point label schemes. .ix is exceptionally useful when dealing with mixed positional and label based hierarchical indexes. . However, when an axis is integer based, ONLY label based access and not positional access is supported. Thus, in such cases, it‚Äôs usually better to be explicit and use .iloc or .loc. . Hmmm, sounds too technical. Let‚Äôs take the help of code to understand these. . Consider a dataframe df . import pandas as pd import numpy as np . df = pd.DataFrame(np.random.randint(0,100,size=(100, 5)), columns=list(&#39;ABCDE&#39;)) . df.head() . A B C D E . 0 84 | 71 | 64 | 93 | 65 | . 1 87 | 17 | 12 | 67 | 80 | . 2 45 | 70 | 12 | 83 | 90 | . 3 56 | 98 | 5 | 88 | 90 | . 4 31 | 70 | 98 | 26 | 33 | . df.shape . (100, 5) . We‚Äôll apply all the three on our dataset: . # Selecting first three rows? df.iloc[:3] . A B C D E . 0 84 | 71 | 64 | 93 | 65 | . 1 87 | 17 | 12 | 67 | 80 | . 2 45 | 70 | 12 | 83 | 90 | . # Selecting first three rows? df.loc[:3] . A B C D E . 0 84 | 71 | 64 | 93 | 65 | . 1 87 | 17 | 12 | 67 | 80 | . 2 45 | 70 | 12 | 83 | 90 | . 3 56 | 98 | 5 | 88 | 90 | . # Selecting first three rows? df.ix[:3] . A B C D E . 0 84 | 71 | 64 | 93 | 65 | . 1 87 | 17 | 12 | 67 | 80 | . 2 45 | 70 | 12 | 83 | 90 | . 3 56 | 98 | 5 | 88 | 90 | . Apart from iloc, the rest two don‚Äôt really follow the same that points out the first difference: iloc is integer based while the rest aren‚Äôt (Note: loc is exclusively label based, while ix plays the devil‚Äôs advocate). . loc and ix select values till the index label 3 i.e. we get values of [0,1,2,3] . Let‚Äôs correct the loc and ix to select first 3 rows: . # since both behave as label based, let&#39;s write them as: print (&quot;::::The output for loc::::&quot;) print (df.loc[:2]) print (&quot;::::The output for ix::::&quot;) print (df.ix[:2]) . ::::The output for loc:::: A B C D E 0 84 71 64 93 65 1 87 17 12 67 80 2 45 70 12 83 90 ::::The output for ix:::: A B C D E 0 84 71 64 93 65 1 87 17 12 67 80 2 45 70 12 83 90 . Now, the question arises why do we need loc or ix when the insanely simple iloc solves our problems? . Let‚Äôs consider the following scenario where we need to slice select columns from the dataframe using iloc: . # Selecting the column&#39;s [A,C] for the first 3 rows df.iloc[:3, [&#39;A&#39;, &#39;C&#39;]] . TypeError Traceback (most recent call last) &lt;ipython-input-9-2f83469716a2&gt; in &lt;module&gt;() 1 # Selecting the column&#39;s [A,C] for the first 3 rows -&gt; 2 df.iloc[:3, [&#39;A&#39;, &#39;C&#39;]] /home/pratos/miniconda3/lib/python3.5/site-packages/pandas/core/indexing.py in __getitem__(self, key) 1308 1309 if type(key) is tuple: -&gt; 1310 return self._getitem_tuple(key) 1311 else: 1312 return self._getitem_axis(key, axis=0) /home/pratos/miniconda3/lib/python3.5/site-packages/pandas/core/indexing.py in _getitem_tuple(self, tup) 1558 def _getitem_tuple(self, tup): 1559 -&gt; 1560 self._has_valid_tuple(tup) 1561 try: 1562 return self._getitem_lowerdim(tup) /home/pratos/miniconda3/lib/python3.5/site-packages/pandas/core/indexing.py in _has_valid_tuple(self, key) 149 if i &gt;= self.obj.ndim: 150 raise IndexingError(&#39;Too many indexers&#39;) --&gt; 151 if not self._has_valid_type(k, i): 152 raise ValueError(&quot;Location based indexing can only have [%s] &quot; 153 &quot;types&quot; % self._valid_types) /home/pratos/miniconda3/lib/python3.5/site-packages/pandas/core/indexing.py in _has_valid_type(self, key, axis) 1528 return self._is_valid_integer(key, axis) 1529 elif is_list_like_indexer(key): -&gt; 1530 return self._is_valid_list_like(key, axis) 1531 return False 1532 /home/pratos/miniconda3/lib/python3.5/site-packages/pandas/core/indexing.py in _is_valid_list_like(self, key, axis) 1551 ax = self.obj._get_axis(axis) 1552 l = len(ax) -&gt; 1553 if len(arr) and (arr.max() &gt;= l or arr.min() &lt; -l): 1554 raise IndexError(&quot;positional indexers are out-of-bounds&quot;) 1555 /home/pratos/miniconda3/lib/python3.5/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims) 24 # small reductions 25 def _amax(a, axis=None, out=None, keepdims=False): &gt; 26 return umr_maximum(a, axis, None, out, keepdims) 27 28 def _amin(a, axis=None, out=None, keepdims=False): TypeError: cannot perform reduce with flexible type . Whoa! Up there‚Äôs a mess homie! . Unlike numpy, pandas have a label based columns and there‚Äôs a need for a better control over selection of columns in a dataframe. loc provides that with it‚Äôs label based selection (sometimes if not used properly might leave the practitioner with a numb brain). Let‚Äôs see whether we can do that with loc . df.loc[:2, [&#39;A&#39;, &#39;C&#39;]] . A C . 0 84 | 64 | . 1 87 | 12 | . 2 45 | 12 | . Note: loc includes last element, iloc doesn‚Äôt. So, the above behaviour while selecting rows explains that. . Sweet! It seems loc is awesome! What about ix, would it be the same? . Note: ix has a very dividing opinion, in the pandas documentation itself the maintainers point towards using iloc and loc whenever a sane dataframe is being presented. Just to avoid the confusion that prevails from mixture label based and integer based slicing. . If loc is a Katana, then ix is Iron aged double edged swords. Let‚Äôs refer the documentation definition of ix again: . ix supports mixed integer and label based access. It is primarily label based, but will fall back to integer positional access unless the corresponding axis is of integer type. .ix is the most general and will support any of the inputs in .loc and .iloc. .ix also supports floating point label schemes. .ix is exceptionally useful when dealing with mixed positional and label based hierarchical indexes. . The base behavior of ix is illustrated as below: . df.ix[3] . A 56 B 98 C 5 D 88 E 90 Name: 3, dtype: int64 . df.ix[3] returns by default the value of the 3rd row. df.ix[3,] would give the similar results. . df.ix[3,] . A 56 B 98 C 5 D 88 E 90 Name: 3, dtype: int64 . # A more &quot;complex&quot; query using ix # Hybrid approach df.ix[1:3, [&#39;A&#39;, &#39;C&#39;]] . A C . 1 87 | 12 | . 2 45 | 12 | . 3 56 | 5 | . # Selecting rows from 1 to 3, and columns 1 to 2 # Pure Index based df.ix[1:3, 1:2] . B . 1 17 | . 2 70 | . 3 98 | . From the above two examples, we can understand how handy ix. Almost like being rescued by Gandalf himself with his sword, Glamdrig! (At least I felt like today üòä) . Source: Cultjer . With all the small snippets, I hope the basic demons about our three musketeers are exorcised. A small real life dataset would help in getting a feel of the things. . winered = pd.read_csv(&#39;winequality-red.csv&#39;, sep=&#39;;&#39;) . winered.head(5) . fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol quality . 0 7.4 | 0.70 | 0.00 | 1.9 | 0.076 | 11.0 | 34.0 | 0.9978 | 3.51 | 0.56 | 9.4 | 5 | . 1 7.8 | 0.88 | 0.00 | 2.6 | 0.098 | 25.0 | 67.0 | 0.9968 | 3.20 | 0.68 | 9.8 | 5 | . 2 7.8 | 0.76 | 0.04 | 2.3 | 0.092 | 15.0 | 54.0 | 0.9970 | 3.26 | 0.65 | 9.8 | 5 | . 3 11.2 | 0.28 | 0.56 | 1.9 | 0.075 | 17.0 | 60.0 | 0.9980 | 3.16 | 0.58 | 9.8 | 6 | . 4 7.4 | 0.70 | 0.00 | 1.9 | 0.076 | 11.0 | 34.0 | 0.9978 | 3.51 | 0.56 | 9.4 | 5 | . # Select pH scores having less than 3 with quality equal to 6 winered.ix[:,[&#39;pH&#39;, &#39;quality&#39;]].query(&#39;pH &lt; 3 &amp; quality == 6&#39;) . pH quality . 86 2.93 | 6 | . 91 2.93 | 6 | . 464 2.98 | 6 | . 544 2.86 | 6 | . 614 2.87 | 6 | . 667 2.94 | 6 | . 669 2.94 | 6 | . 1017 2.89 | 6 | . 1018 2.89 | 6 | . 1319 2.90 | 6 | . As the above query, we can go on with many such. Hope this has been helpful for the readers. Do comment and correct if any inconsistencies. . Sources: . Pandas: Indexing and Selecting | Is ix always better than loc and iloc? | Must read Github issue on iloc, loc and ix |",
            "url": "https://pratos.github.io/shodh/2017/03/07/pandas-indexing-confusion.html",
            "relUrl": "/2017/03/07/pandas-indexing-confusion.html",
            "date": " ‚Ä¢ Mar 7, 2017"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "https://pratos.github.io/shodh/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://pratos.github.io/shodh/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}